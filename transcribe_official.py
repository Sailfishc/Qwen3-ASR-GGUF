#!/usr/bin/env python3
# coding=utf-8
"""
ä½¿ç”¨ Qwen3-ASR-0.6B æ¨¡å‹è½¬å½•éŸ³é¢‘æ–‡ä»¶
ç›´æ¥è°ƒç”¨å®˜æ–¹ qwen_asr åŒ…ï¼Œæ— éœ€æ‰‹åŠ¨è½¬æ¢æ¨¡å‹
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from qwen_asr import Qwen3ASRModel

def transcribe(audio_path: str, model_name: str = "Qwen/Qwen3-ASR-0.6B"):
    """
    ä½¿ç”¨å®˜æ–¹ Qwen3-ASR æ¨¡å‹è½¬å½•éŸ³é¢‘
    
    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        model_name: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä½¿ç”¨ 0.6B
    """
    print(f"ğŸ¤ å¼€å§‹è½¬å½•ï¼š{audio_path}")
    print(f"ğŸ“¦ ä½¿ç”¨æ¨¡å‹ï¼š{model_name}")
    
    # åŠ è½½æ¨¡å‹ï¼ˆä¼šè‡ªåŠ¨ä» ModelScope ä¸‹è½½ï¼‰
    print("â³ æ­£åœ¨åŠ è½½æ¨¡å‹ï¼ˆé¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½ï¼‰...")
    asr = Qwen3ASRModel.from_pretrained(
        model_name,
        device_map="cpu",  # ä½¿ç”¨ CPU
        dtype=torch.float32
    )
    
    print("ğŸš€ å¼€å§‹è½¬å½•...")
    
    # æ‰§è¡Œè½¬å½•
    results = asr.transcribe(
        audio=audio_path,
        language=None,  # è‡ªåŠ¨è¯†åˆ«è¯­è¨€
        return_time_stamps=False
    )
    
    # è¾“å‡ºç»“æœ
    print("\n" + "="*60)
    print("ğŸ“ è½¬å½•æ–‡æœ¬:")
    print("="*60)
    
    for i, result in enumerate(results):
        print(f"\n[ç‰‡æ®µ {i+1}]")
        print(f"è¯­è¨€ï¼š{result.language}")
        print(f"æ–‡æœ¬ï¼š{result.text}")
    
    print("="*60)
    
    # åˆå¹¶æ‰€æœ‰æ–‡æœ¬
    full_text = " ".join([r.text for r in results])
    print(f"\nå®Œæ•´æ–‡æœ¬:\n{full_text}")
    
    return full_text

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ç”¨æ³•ï¼špython3 transcribe_official.py <éŸ³é¢‘æ–‡ä»¶> [æ¨¡å‹åç§°]")
        print("ç¤ºä¾‹ï¼špython3 transcribe_official.py test_audio.wav")
        print("      python3 transcribe_official.py test_audio.wav Qwen/Qwen3-ASR-0.6B")
        sys.exit(1)
    
    audio_file = sys.argv[1]
    model_name = sys.argv[2] if len(sys.argv) > 2 else "Qwen/Qwen3-ASR-0.6B"
    
    import torch
    transcribe(audio_file, model_name)
