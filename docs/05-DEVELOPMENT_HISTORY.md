# Qwen3-ASR-GGUF å¼€å‘å†ç¨‹

> æœ¬æ–‡æ¡£é€šè¿‡ Git æäº¤å†å²é€†å‘åˆ†æï¼Œè¿˜åŸä½œè€…ä»é›¶æ„å»ºé¡¹ç›®çš„å®Œæ•´è¿‡ç¨‹  
> åˆ†ææ—¥æœŸï¼š2026-02-23  
> æ€»æäº¤æ•°ï¼š50+  
> å¼€å‘å‘¨æœŸï¼šçº¦ 2 ä¸ªæœˆï¼ˆ2026-02 è‡³ä»Šï¼‰  
> **æ¨èé˜…è¯»é¡ºåºï¼šç¬¬ â‘¢ é¡ºä½**ï¼ˆç†è§£é¡¹ç›®æ„å»ºè¿‡ç¨‹ï¼‰

---

## ğŸ“š é˜…è¯»æŒ‡å—

### åœ¨æ–‡æ¡£ä½“ç³»ä¸­çš„ä½ç½®

| é¡ºä½ | æ–‡æ¡£ | æ–‡ä»¶å | ç›®æ ‡è¯»è€… | é¢„è®¡è€—æ—¶ |
|:----:|------|--------|----------|----------|
| **â‘ ** | [é¡¹ç›®æ¶æ„](./02-ARCHITECTURE.md) | `02-ARCHITECTURE.md` | æƒ³äº†è§£é¡¹ç›®æ•´ä½“è®¾è®¡ | 1-2 å°æ—¶ |
| **â‘¡** | [é›†æˆæŒ‡å—](./03-INTEGRATION.md) | `03-INTEGRATION.md` | æƒ³å¿«é€Ÿä½¿ç”¨é¡¹ç›® | 1-2 å°æ—¶ |
| **â‘¢** | **å¼€å‘å†ç¨‹** | `05-DEVELOPMENT_HISTORY.md` | **æƒ³äº†è§£é¡¹ç›®å¦‚ä½•æ„å»º** | **2-3 å°æ—¶** |
| **â‘£** | [å­¦ä¹ è®¡åˆ’](./06-LEARNING_PLAN.md) | `06-LEARNING_PLAN.md` | æƒ³æ·±å…¥ç†è§£åŸç† | 4-12 å‘¨ |
| **â‘¤** | [å¯¼å‡ºæŒ‡å—](./EXPORT_GUIDE.md) | `EXPORT_GUIDE.md` | æƒ³è½¬æ¢è‡ªå·±çš„æ¨¡å‹ | 2-4 å°æ—¶ |
| **â‘¥** | [æºç è§£æ](./SOURCE_CODE.md) | `SOURCE_CODE.md` | æƒ³ä¿®æ”¹/æ‰©å±•åŠŸèƒ½ | 4-8 å‘¨ |

### æœ¬æ–‡æ¡£ä»·å€¼

- âœ… äº†è§£çœŸå®é¡¹ç›®çš„æ¼”è¿›è¿‡ç¨‹
- âœ… å­¦ä¹ å·¥ç¨‹åŒ–æ€ç»´
- âœ… ç†è§£æŠ€æœ¯å†³ç­–èƒŒåçš„åŸå› 
- âœ… ä¸ºè‡ªå·±çš„é¡¹ç›®æä¾›å‚è€ƒ

### é˜…è¯»å»ºè®®

```
å¦‚æœä½ ï¼š
â”œâ”€ æƒ³äº†è§£ä½œè€…æ˜¯å¦‚ä½•ä¸€æ­¥æ­¥æ„å»ºè¿™ä¸ªé¡¹ç›®çš„ â†’ å®Œæ•´é˜…è¯»
â”œâ”€ æƒ³å­¦ä¹ å¦‚ä½•ä»é›¶å¼€å§‹ä¸€ä¸ª ML å·¥ç¨‹ â†’ é‡ç‚¹çœ‹é˜¶æ®µä¸€ã€äºŒ
â”œâ”€ æƒ³ç†è§£å…³é”®è®¾è®¡å†³ç­– â†’ é‡ç‚¹çœ‹"å…³é”®æŠ€æœ¯å†³ç­–åˆ†æ"ç« èŠ‚
â””â”€ æƒ³é¿å…å¸¸è§å‘ â†’ é‡ç‚¹çœ‹"å…³é”® Bug ä¸è§£å†³æ–¹æ¡ˆ"ç« èŠ‚
```

---

## ğŸ¯ é¡¹ç›®æ¼”è¿›æ—¶é—´çº¿

```
2026-02 ä¸Šæ—¬                    2026-02 ä¸­æ—¬                   2026-02 ä¸‹æ—¬
     â”‚                               â”‚                              â”‚
     â–¼                               â–¼                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ é˜¶æ®µä¸€   â”‚                  â”‚ é˜¶æ®µäºŒ   â”‚                  â”‚ é˜¶æ®µä¸‰   â”‚
â”‚ æ¨¡å‹å¯¼å‡º â”‚        â†’         â”‚ æ¨ç†éªŒè¯ â”‚        â†’         â”‚ å·¥ç¨‹ä¼˜åŒ– â”‚
â”‚ (2å‘¨)    â”‚                  â”‚ (1å‘¨)    â”‚                  â”‚ (1å‘¨)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                               â”‚                              â”‚
     â€¢ åˆ†æå®˜æ–¹æ¨¡å‹                 â€¢ æ„å»ºæ¨ç†è„šæœ¬                 â€¢ æ€§èƒ½ä¼˜åŒ–
     â€¢ å¯¼å‡º Encoder                 â€¢ éªŒè¯ç²¾åº¦                     â€¢ æ‰“åŒ…å‘å¸ƒ
     â€¢ å¯¼å‡º Decoder                 â€¢ é›†æˆ Aligner                 â€¢ æ–‡æ¡£å®Œå–„
     â€¢ å¯¼å‡º Mel ç‰¹å¾                â€¢ é•¿éŸ³é¢‘æµ‹è¯•                   â€¢ Bug ä¿®å¤
```

---

## é˜¶æ®µä¸€ï¼šæ¨¡å‹å¯¼å‡ºï¼ˆçº¦ 2 å‘¨ï¼‰

### Week 1: æ¢ç´¢ä¸éªŒè¯

#### Day 1-3: ç†è§£å®˜æ–¹æ¨¡å‹

**æäº¤**: `c556c2d åˆæ­¥æäº¤` â†’ `18228b2 å®˜æ–¹æ¨ç†`

ä½œè€…é¦–å…ˆåšçš„äº‹æƒ…ï¼š

```python
# 1. åŠ è½½å®˜æ–¹æ¨¡å‹ï¼Œç†è§£ç»“æ„
from transformers import AutoModel

model = AutoModel.from_pretrained("Qwen/Qwen3-ASR-1.7B")

# 2. åˆ†ææ¨¡å‹ç»„ä»¶
print(model.model.thinker.audio_tower)  # Encoder éƒ¨åˆ†
print(model.model.thinker.llm)          # Decoder éƒ¨åˆ†
```

**å…³é”®å‘ç°**:
- æ¨¡å‹åˆ†ä¸º Audio Tower (Encoder) å’Œ LLM (Decoder)
- Encoder åˆåˆ†å‰ç«¯ (CNN) å’Œåç«¯ (Transformer)
- éœ€è¦å¯¼å‡ºçš„ç»„ä»¶ï¼šMel æ»¤æ³¢å™¨ã€Encoderã€Decoder

#### Day 4-7: å¯¼å‡º Encoder

**æäº¤**: `f75b043 ä½™å¼¦ç›¸ä¼¼åº¦éªŒè¯é€šè¿‡` â†’ `52f6c0c å·ç§¯å‰ç«¯éªŒè¯é€šè¿‡`

**é‡åˆ°çš„ç¬¬ä¸€ä¸ªæŒ‘æˆ˜**: Encoder ç»“æ„å¤æ‚

```
åŸå§‹æ¨¡å‹ç»“æ„:
Audio Tower
â”œâ”€â”€ Frontend (CNN)
â”‚   â”œâ”€â”€ Conv1d + GELU
â”‚   â”œâ”€â”€ Conv1d + GELU
â”‚   â””â”€â”€ Conv1d
â”œâ”€â”€ Positional Encoding
â””â”€â”€ Backend (Transformer)
    â””â”€â”€ 24 å±‚ Transformer
```

**è§£å†³æ–¹æ¡ˆ**: åˆ†æ­¥å¯¼å‡º

```python
# æ­¥éª¤ 1: å¯¼å‡ºå‰ç«¯ CNN
class Qwen3ASRFrontendOnnx(nn.Module):
    def __init__(self, audio_tower):
        super().__init__()
        # åªå–å‰ç«¯çš„å·ç§¯éƒ¨åˆ†
        self.conv1 = audio_tower.conv1
        self.conv2 = audio_tower.conv2
        self.conv3 = audio_tower.conv3
    
    def forward(self, x):
        x = self.conv1(x)  # (B, 128, T) -> (B, 384, T/2)
        x = F.gelu(x)
        x = self.conv2(x)  # -> (B, 384, T/4)
        x = F.gelu(x)
        x = self.conv3(x)  # -> (B, 896, T/4)
        return x
```

**éªŒè¯æ–¹æ³•**: ä½™å¼¦ç›¸ä¼¼åº¦éªŒè¯

```python
# éªŒè¯å¯¼å‡ºç²¾åº¦
def verify_cosine_similarity(onnx_output, torch_output):
    similarity = cosine_similarity(onnx_output, torch_output)
    assert similarity > 0.99, f"ç›¸ä¼¼åº¦ {similarity} è¿‡ä½ï¼"
```

### Week 2: è§£å†³æ˜¾å­˜é—®é¢˜

#### Day 8-10: æ˜¾å­˜çˆ†ç‚¸

**æäº¤**: `eae0258 å°è¯•è§£å†³å·ç§¯å ç”¨å†…å­˜çš„é—®é¢˜`

**é—®é¢˜**: ä¸€æ¬¡æ€§å¯¼å‡ºæ•´ä¸ª Encoderï¼Œé•¿éŸ³é¢‘å¯¼è‡´ OOM

```
é”™è¯¯ç°è±¡:
CUDA out of memory. Tried to allocate 20.00 GiB
```

**åˆ†æ**: CNN å‰ç«¯åœ¨å¤„ç†é•¿åºåˆ—æ—¶ï¼Œä¸­é—´æ¿€æ´»å€¼å ç”¨å·¨å¤§æ˜¾å­˜

**ç¬¬ä¸€æ¬¡å°è¯•**: å¤šé€šé“å·ç§¯å–ä»£ batch
- æ•ˆæœä¸ä½³ï¼Œä»ç„¶å ç”¨å¤§é‡æ˜¾å­˜

**ç¬¬äºŒæ¬¡å°è¯•**: **åˆ†ä½“ Encoder**ï¼ˆå…³é”®å†³ç­–ï¼‰

**æäº¤**: `da0590c ä½¿ç”¨åˆ†ä½“çš„ encoder`

```python
# å…³é”®åˆ›æ–°ï¼šå‰ç«¯åˆ†æ®µå¤„ç†
class QwenAudioEncoder:
    def __init__(self, frontend_path, backend_path):
        self.sess_fe = ort.InferenceSession(frontend_path)  # CNN
        self.sess_be = ort.InferenceSession(backend_path)   # Transformer
    
    def encode(self, audio):
        # 1. æå– Mel
        mel = self.mel_extractor(audio)  # (128, T)
        
        # 2. å‰ç«¯åˆ†æ®µå¤„ç†ï¼ˆå…³é”®ï¼ï¼‰
        chunk_size = 100
        outputs = []
        for i in range(0, mel.shape[1], chunk_size):
            chunk = mel[:, i:i+chunk_size]
            out = self.sess_fe.run(None, {"chunk_mel": chunk})
            outputs.append(out)
        
        # 3. æ‹¼æ¥åä¼ ç»™åç«¯
        hidden = np.concatenate(outputs, axis=1)
        return self.sess_be.run(None, {"hidden_states": hidden})
```

**æ”¶ç›Š**: æ˜¾å­˜å ç”¨ä» 20GB é™è‡³ <1GB

#### Day 11-14: å¯¼å‡º Decoder å’Œ Aligner

**æäº¤**: `ba5983e gguf å¯¼å‡ºå¿…é¡»` â†’ `15b8074 æˆåŠŸè·‘é€š aligner`

**Decoder å¯¼å‡ºæŒ‘æˆ˜**: 
- å®˜æ–¹ä½¿ç”¨ HuggingFace Transformers
- éœ€è¦è½¬æ¢ä¸º GGUF æ ¼å¼ä¾› llama.cpp ä½¿ç”¨

**è§£å†³æ–¹æ¡ˆ**: å€Ÿç”¨ llama.cpp çš„ convert_hf_to_gguf

```python
# å…³é”®è¡¥ä¸ï¼šè®©è½¬æ¢å™¨æ”¯æŒ Qwen3-ASR çš„ç‰¹æ®Šç»“æ„
def patched_load_hparams(dir_model: Path):
    with open(dir_model / "config.json") as f:
        config = json.load(f)
    
    # é€‚é… Qwen3-ASR çš„ç‰¹æ®Šå­—æ®µå
    if "llm_config" in config:
        config["text_config"] = config["llm_config"]
    
    return config
```

**Aligner æ¨¡å‹å¯¼å‡º**:
- åŒæ ·çš„æµç¨‹å¯¼å‡º Aligner Encoder
- å‘ç°ç»´åº¦ä¸åŒï¼šASR è¾“å‡º 896 ç»´ï¼ŒAligner è¾“å‡º 1024 ç»´
- **å…³é”®ä¿®æ”¹**: åŠ¨æ€è·å–ç»´åº¦

```python
# å…¼å®¹ ASR å’Œ Aligner
conv_out = self.conv3(x)  # å¯èƒ½æ˜¯ 896 æˆ– 1024
dim = conv_out.shape[-1]  # åŠ¨æ€è·å–
```

---

## é˜¶æ®µäºŒï¼šæ¨ç†éªŒè¯ï¼ˆçº¦ 1 å‘¨ï¼‰

### Week 3: æ„å»ºæ¨ç†ç®¡é“

#### Day 15-17: åŸºç¡€æ¨ç†

**æäº¤**: `c021cc0 åˆæ­¥æ„é€ å¼•æ“` â†’ `d930989 encoder æˆåŠŸé›†æˆåˆ°è½¬å½•è„šæœ¬ä¸­`

**ç¬¬ä¸€ä¸ªå¯è¿è¡Œçš„æ¨ç†è„šæœ¬**:

```python
# 21-Run-ASR.py çš„é›å½¢
class QwenASREngine:
    def __init__(self, model_dir):
        # 1. åŠ è½½ Encoder
        self.encoder = QwenAudioEncoder(
            frontend_path=f"{model_dir}/frontend.onnx",
            backend_path=f"{model_dir}/backend.onnx"
        )
        
        # 2. åŠ è½½ Decoder (llama.cpp)
        self.model = llama.LlamaModel(f"{model_dir}/decoder.gguf")
        self.ctx = llama.LlamaContext(self.model, n_ctx=2048)
    
    def transcribe(self, audio_path):
        # 1. ç¼–ç 
        audio_emb = self.encoder.encode(audio)
        
        # 2. æ„å»º Prompt
        prompt = self.build_prompt(audio_emb)
        
        # 3. è§£ç 
        text = self.decode(prompt)
        return text
```

**é‡åˆ°çš„å‘**:
- llama.cpp çš„ batch æ¥å£ä¸ç†Ÿæ‚‰
- Token embedding æ³¨å…¥æ–¹å¼é”™è¯¯
- Prompt æ ¼å¼ä¸å®˜æ–¹ä¸ä¸€è‡´

#### Day 18-19: å¯¹é½æ—¶é—´æˆ³

**æäº¤**: `17c63f6 é›†æˆ aligner æ—¶é—´æˆ³äº†ï¼Œä½†é€Ÿåº¦æœ‰äº›æ…¢`

**é›†æˆç­–ç•¥**:
```
åŸå§‹æµç¨‹:
éŸ³é¢‘ â†’ Encoder â†’ Decoder â†’ æ–‡æœ¬

æ”¹è¿›æµç¨‹:
éŸ³é¢‘ â†’ Encoder â†’ Decoder â†’ æ–‡æœ¬
                          â†“
                     åˆ†æ®µéŸ³é¢‘ + æ–‡æœ¬ â†’ Aligner â†’ æ—¶é—´æˆ³
```

**æ€§èƒ½é—®é¢˜**: Aligner ä¸²è¡Œæ‰§è¡Œï¼Œæ‹–æ…¢æ•´ä½“é€Ÿåº¦

**åˆæ­¥ä¼˜åŒ–**:
```python
# ä½¿ç”¨å¤šè¿›ç¨‹å¹¶è¡Œ
from multiprocessing import Process

align_process = Process(target=align_worker)
align_process.start()
```

#### Day 20-21: é•¿éŸ³é¢‘æµ‹è¯•

**æäº¤**: `4b3b4a6 é€šè¿‡é•¿éŸ³é¢‘æµ‹è¯•ï¼Œå¯å¯¼å‡º srt`

**æµå¼å¤„ç†ç­–ç•¥**:
```python
# 40 ç§’åˆ‡ç‰‡ + è®°å¿†ä¸Šä¸‹æ–‡
chunk_size = 40.0
memory_num = 1

def process_long_audio(audio):
    chunks = split_audio(audio, chunk_size)
    memory = deque(maxlen=memory_num)
    
    for chunk in chunks:
        # æ‹¼æ¥å†å²è®°å¿†
        full_audio = concatenate(memory + [chunk])
        text = transcribe_chunk(full_audio)
        memory.append((chunk, text))
```

**éªŒè¯æˆåŠŸ**:
- 50 åˆ†é’ŸéŸ³é¢‘å¯ä»¥å®Œæ•´è½¬å½•
- SRT å­—å¹•æ­£å¸¸ç”Ÿæˆ

---

## é˜¶æ®µä¸‰ï¼šå·¥ç¨‹ä¼˜åŒ–ï¼ˆçº¦ 1 å‘¨ï¼‰

### Week 4: æ€§èƒ½ä¸å·¥ç¨‹åŒ–

#### Day 22-24: é‡åŒ–ä¸ä¼˜åŒ–

**æäº¤**: `ab498eb å¯¹å¯¼å‡ºçš„ fp32 encoder ä¼˜åŒ–åˆå¹¶gelu`

**ONNX ä¼˜åŒ–æµç¨‹**:
```
FP32 (åŸå§‹) 
  â†’ ä¼˜åŒ– (ç®—å­èåˆã€å¸¸é‡æŠ˜å )
  â†’ FP16 (æ˜¾å­˜å‡åŠ)
  â†’ INT8 (ç›¸ä¼¼åº¦ 98%)
  â†’ INT4 (ç›¸ä¼¼åº¦ 96%ï¼Œæ¨è)
```

**é‡åŒ–æ”¶ç›Š**:
- Encoder æ˜¾å­˜: 473MB â†’ 120MB (INT4)
- é€Ÿåº¦æå‡: 30%

**Decoder é‡åŒ–**:
```bash
# å…ˆå¯¼å‡º FP16ï¼Œå†é‡åŒ–ä¸º Q4_K
./llama-quantize model.gguf model_q4_k.gguf Q4_K
```

#### Day 25-27: å¯åŠ¨ä¼˜åŒ–

**æäº¤**: `3917d4b ç»Ÿè®¡å’Œä¼˜åŒ–å¯åŠ¨æ—¶é—´`

**å‘ç°çš„é—®é¢˜**:
- å¯åŠ¨éœ€è¦ 10+ ç§’
- ä¸»è¦è€—æ—¶åœ¨: librosa å¯¼å…¥ã€æ¨¡å‹åŠ è½½ã€é¢„çƒ­

**ä¼˜åŒ–æªæ–½**:

1. **ç§»é™¤ librosa ä¾èµ–**
   ```python
   # åŸæ¥
   import librosa
   mel = librosa.feature.melspectrogram(...)
   
   # ä¼˜åŒ–å
   from scipy.signal import get_window
   # ç”¨ NumPy + SciPy å®ç°ï¼Œæ¶ˆé™¤ Numba JIT å»¶è¿Ÿ
   ```

2. **Mel çŸ©é˜µåŠ¨æ€ç”Ÿæˆ**
   ```python
   # åŸæ¥: é¢„å…ˆè®¡ç®—ä¿å­˜
   mel_filters = np.load("mel_filters.npy")
   
   # ä¼˜åŒ–å: åŠ¨æ€ç”Ÿæˆï¼Œå¯åŠ¨å¿« 3 ç§’
   self.filters = self._generate_filters(...)
   ```

3. **å¼‚æ­¥é¢„çƒ­**
   ```python
   # åœ¨è¾…åŠ©è¿›ç¨‹ä¸­é¢„çƒ­ï¼Œä¸é˜»å¡ä¸»è¿›ç¨‹
   warmup_proc = Process(target=warmup_encoder)
   ```

#### Day 28-30: å‘½ä»¤è¡Œå·¥å…·ä¸æ‰“åŒ…

**æäº¤**: `f157e09 åˆæ­¥çš„å‘½ä»¤è¡Œè½¬å½•å·¥å…·` â†’ `4f9b7c5 æ‰“åŒ…è„šæœ¬`

**å‘½ä»¤è¡Œå·¥å…·è®¾è®¡**:
```python
# transcribe.py
import typer

app = typer.Typer()

@app.command()
def transcribe(
    files: List[Path],
    model_dir: str = "model",
    use_dml: bool = True,
    language: Optional[str] = None
):
    # å®ç°...
```

**PyInstaller æ‰“åŒ…**:
```python
# build.spec
# å…³é”®é…ç½®ï¼š
# 1. æ’é™¤ torch/transformersï¼ˆå¤ªå¤§äº†ï¼‰
# 2. é“¾æ¥æ¨¡å‹æ–‡ä»¶å¤¹ï¼ˆä¸å¤åˆ¶ï¼‰
# 3. åŒ…å« llama.cpp DLL
```

---

## ğŸ¯ å…³é”®æŠ€æœ¯å†³ç­–åˆ†æ

### å†³ç­– 1: ä¸ºä»€ä¹ˆé€‰æ‹© ONNX + GGUF æ··åˆæ¶æ„ï¼Ÿ

**å¯é€‰æ–¹æ¡ˆå¯¹æ¯”**:

| æ–¹æ¡ˆ | ä¼˜ç‚¹ | ç¼ºç‚¹ | ä½œè€…é€‰æ‹© |
|------|------|------|----------|
| çº¯ PyTorch | ç®€å•ç›´æ¥ | æ˜¾å­˜å ç”¨é«˜ï¼Œé€Ÿåº¦æ…¢ | âŒ |
| çº¯ ONNX | ç»Ÿä¸€æ ¼å¼ | Decoder å¤æ‚ï¼Œä¸æ”¯æŒ KV Cache | âŒ |
| çº¯ GGUF | ä½“ç§¯å° | Encoder é‡åŒ–æŸå¤±å¤§ | âŒ |
| **ONNX + GGUF** | **å„å–æ‰€é•¿** | **é›†æˆå¤æ‚** | âœ… |

**ç†ç”±**:
- Encoder ç”¨ ONNX: æ”¯æŒ DML/Vulkanï¼Œé‡åŒ–ç²¾åº¦å¯æ§
- Decoder ç”¨ GGUF: llama.cpp æˆç†Ÿï¼Œæ”¯æŒ KV Cache

### å†³ç­– 2: ä¸ºä»€ä¹ˆåˆ†ä½“ Encoderï¼Ÿ

**åŸå§‹é—®é¢˜**: é•¿éŸ³é¢‘å¯¼è‡´æ˜¾å­˜çˆ†ç‚¸

**è§£å†³æ–¹æ¡ˆæ¼”è¿›**:

```
å°è¯• 1: å‡å° batch size
  â†“ æ•ˆæœä¸ä½³ï¼ŒCNN ä¸­é—´æ¿€æ´»ä¾ç„¶å¤§

å°è¯• 2: å¤šé€šé“å·ç§¯
  â†“ ä»£ç å¤æ‚ï¼Œæ”¶ç›Šæœ‰é™

å°è¯• 3: åˆ†ä½“ Encoderï¼ˆæœ€ç»ˆæ–¹æ¡ˆï¼‰
  âœ“ Frontend åˆ†æ®µå¤„ç†ï¼ŒBackend å®Œæ•´å¤„ç†
  âœ“ æ˜¾å­˜å ç”¨ç¨³å®šï¼Œä¸éŸ³é¢‘é•¿åº¦æ— å…³
```

### å†³ç­– 3: ä¸ºä»€ä¹ˆç”¨å¤šè¿›ç¨‹è€Œéå¤šçº¿ç¨‹ï¼Ÿ

**åŸå› **:
1. **GIL é™åˆ¶**: Python å¤šçº¿ç¨‹æ— æ³•åˆ©ç”¨å¤šæ ¸
2. **ONNX Runtime**: åœ¨å¤šè¿›ç¨‹ä¸­å¯ä»¥ç‹¬ç«‹ä½¿ç”¨ DML
3. **éš”ç¦»æ€§**: Encoder å´©æºƒä¸å½±å“ä¸»è¿›ç¨‹

```python
# ä¸»è¿›ç¨‹
main_process: ASR è§£ç  + åè°ƒ

# è¾…åŠ©è¿›ç¨‹
worker_process: Encoder + Aligner
```

### å†³ç­– 4: ä¸ºä»€ä¹ˆç§»é™¤ librosaï¼Ÿ

**librosa çš„é—®é¢˜**:
- å¯åŠ¨æ…¢ï¼ˆNumba JIT ç¼–è¯‘ï¼‰
- ä¾èµ–å¤šï¼ˆéœ€è¦ soundfile ç­‰ï¼‰
- åŠŸèƒ½è¿‡å‰©ï¼ˆåªéœ€è¦ Mel æå–ï¼‰

**æ›¿æ¢æ–¹æ¡ˆ**:
```python
# çº¯ NumPy + SciPy å®ç°
class FastWhisperMel:
    def __call__(self, audio):
        # 1. åˆ†å¸§ï¼ˆé›¶æ‹·è´ï¼‰
        frames = np.lib.stride_tricks.as_strided(...)
        
        # 2. FFT
        stft = np.fft.rfft(frames * self.window)
        
        # 3. Mel æ»¤æ³¢
        mel = np.dot(self.filters.T, np.abs(stft)**2)
        
        return np.log10(mel)
```

**æ”¶ç›Š**: å¯åŠ¨æ—¶é—´ä» 6 ç§’é™è‡³ 1 ç§’

---

## ğŸ› å…³é”® Bug ä¸è§£å†³æ–¹æ¡ˆ

### Bug 1: æ—¶é—´æˆ³éå•è°ƒé€’å¢

**ç°è±¡**: å¯¹é½ç»“æœå‡ºç°è´Ÿæ•°æˆ–å€’é€€çš„æ—¶é—´æˆ³

**æ ¹å› **: Aligner è§£ç æ—¶ï¼ŒTimestamp token é¢„æµ‹ä¸ç¨³å®š

**è§£å†³æ–¹æ¡ˆ**: LIS + çº¿æ€§æ’å€¼ç®—æ³•

```python
def fix_timestamps(data):
    # 1. æ‰¾æœ€é•¿é€’å¢å­åºåˆ— (LIS)
    lis_indices = find_lis(data)
    
    # 2. æ ‡è®°å¼‚å¸¸ç‚¹
    is_normal = [i in lis_indices for i in range(len(data))]
    
    # 3. å¼‚å¸¸ç‚¹æ’å€¼
    for i, normal in enumerate(is_normal):
        if not normal:
            data[i] = interpolate(i, left_val, right_val)
```

### Bug 2: Intel é›†æ˜¾è¾“å‡ºä¹±ç 

**ç°è±¡**: è¾“å‡º "!!!!!" æˆ–ä¹±ç 

**æ ¹å› **: Intel é›†æ˜¾ FP16 è®¡ç®—æº¢å‡º

**è§£å†³æ–¹æ¡ˆ**: ç¦ç”¨ FP16

```python
os.environ["GGML_VULKAN_DISABLE_F16"] = "1"
```

### Bug 3: æ˜¾å­˜æŒç»­å¢é•¿

**ç°è±¡**: é•¿éŸ³é¢‘å¤„ç†æ—¶æ˜¾å­˜ä¸æ–­å¢é•¿

**æ ¹å› **: ONNX Runtime çš„å†…å­˜æ± æœªé‡Šæ”¾

**è§£å†³æ–¹æ¡ˆ**: è¿›ç¨‹éš”ç¦»

```python
# æ¯ä¸ªéŸ³é¢‘æ–‡ä»¶ä½¿ç”¨æ–°è¿›ç¨‹
Process(target=process_audio, args=(audio,)).start()
```

---

## ğŸ“Š æ€§èƒ½æ¼”è¿›æ•°æ®

| é˜¶æ®µ | RTF (å®æ—¶ç‡) | æ˜¾å­˜å ç”¨ | å¯åŠ¨æ—¶é—´ | å¤‡æ³¨ |
|------|-------------|----------|----------|------|
| åˆå§‹ | 0.5 | 8GB | 15s | çº¯ PyTorch |
| ä¼˜åŒ– 1 | 0.1 | 4GB | 12s | ONNX å¯¼å‡º |
| ä¼˜åŒ– 2 | 0.08 | 2GB | 8s | åˆ†ä½“ Encoder |
| ä¼˜åŒ– 3 | 0.05 | 900MB | 3s | INT4 é‡åŒ– |
| æœ€ç»ˆ | 0.052 | 900MB | 2.5s | ç§»é™¤ librosa |

---

## ğŸ’¡ ç»™åæ¥è€…çš„å»ºè®®

### å¦‚æœä½ æƒ³å¤åˆ»è¿™ä¸ªé¡¹ç›®...

#### é˜¶æ®µ 1: æ¨¡å‹åˆ†æï¼ˆ1-2 å¤©ï¼‰

```python
# 1. åŠ è½½å®˜æ–¹æ¨¡å‹
from transformers import AutoModel
model = AutoModel.from_pretrained("model_name")

# 2. æ‰“å°æ¨¡å‹ç»“æ„
print(model)

# 3. ç¡®å®šå¯¼å‡ºç»„ä»¶
# - Encoder?
# - Decoder?
# - å…¶ä»–é¢„å¤„ç†?

# 4. éªŒè¯å¯¼å‡ºç²¾åº¦
def verify_export(onnx_path, torch_model, sample_input):
    onnx_out = onnx_inference(onnx_path, sample_input)
    torch_out = torch_model(sample_input)
    assert cosine_similarity(onnx_out, torch_out) > 0.99
```

#### é˜¶æ®µ 2: æœ€å°å¯ç”¨æ¨ç†ï¼ˆ3-5 å¤©ï¼‰

1. **å…ˆè·‘é€šå•æ–‡ä»¶æ¨ç†**
   - ä¸è¦ç®¡å¤šè¿›ç¨‹
   - ä¸è¦ç®¡é•¿éŸ³é¢‘
   - åªè¦çŸ­éŸ³é¢‘èƒ½å‡ºç»“æœ

2. **éªŒè¯ç²¾åº¦**
   - ä¸å®˜æ–¹è¾“å‡ºå¯¹æ¯”
   - ç¡®ä¿è¯¯å·® < 1%

3. **æ·»åŠ åŸºç¡€åŠŸèƒ½**
   - éŸ³é¢‘åŠ è½½
   - ç»“æœä¿å­˜

#### é˜¶æ®µ 3: å·¥ç¨‹åŒ–ï¼ˆ1-2 å‘¨ï¼‰

1. **æ€§èƒ½ä¼˜åŒ–**
   - é‡åŒ–
   - æ‰¹å¤„ç†
   - ç¼“å­˜

2. **ç¨³å®šæ€§**
   - é”™è¯¯å¤„ç†
   - èµ„æºé‡Šæ”¾
   - æ—¥å¿—è®°å½•

3. **æ˜“ç”¨æ€§**
   - å‘½ä»¤è¡Œå·¥å…·
   - é…ç½®æ–‡ä»¶
   - æ–‡æ¡£

### å…³é”®å·¥å…·é“¾

```
æ¨¡å‹åˆ†æ:
â”œâ”€â”€ Netron (å¯è§†åŒ– ONNX)
â”œâ”€â”€ transformers (åŠ è½½å®˜æ–¹æ¨¡å‹)
â””â”€â”€ torch.onnx.export (å¯¼å‡º ONNX)

æ¨ç†éªŒè¯:
â”œâ”€â”€ onnxruntime (CPU/GPU æ¨ç†)
â”œâ”€â”€ llama.cpp (GGUF æ¨ç†)
â””â”€â”€ scipy (éŸ³é¢‘å¤„ç†)

æ€§èƒ½ä¼˜åŒ–:
â”œâ”€â”€ onnxoptimizer (ONNX ä¼˜åŒ–)
â”œâ”€â”€ onnxruntime.quantization (é‡åŒ–)
â””â”€â”€ llama-quantize (GGUF é‡åŒ–)

å·¥ç¨‹åŒ–:
â”œâ”€â”€ PyInstaller (æ‰“åŒ…)
â”œâ”€â”€ typer (CLI)
â””â”€â”€ rich (ç»ˆç«¯ç¾åŒ–)
```

---

## ğŸ“ ä»æœ¬é¡¹ç›®å­¦åˆ°çš„å·¥ç¨‹æ€ç»´

### 1. æ¸è¿›å¼å¼€å‘

ä¸è¦è¯•å›¾ä¸€æ¬¡æ€§å®Œæˆæ‰€æœ‰åŠŸèƒ½ï¼š
```
âœ— é”™è¯¯: å…ˆè®¾è®¡å®Œç¾æ¶æ„ï¼Œå†å†™ä»£ç 
âœ“ æ­£ç¡®: å…ˆè·‘é€šæœ€å°å¯ç”¨ç‰ˆæœ¬ï¼Œå†é€æ­¥ä¼˜åŒ–
```

### 2. æ•°æ®é©±åŠ¨ä¼˜åŒ–

æ¯ä¸ªä¼˜åŒ–éƒ½è¦ç”¨æ•°æ®éªŒè¯ï¼š
```python
# é‡åŒ–å‰
similarity = calculate_similarity(fp32_output, fp16_output)
print(f"FP16 ç›¸ä¼¼åº¦: {similarity}")  # å¿…é¡» > 99%

# é‡åŒ–å
similarity = calculate_similarity(fp32_output, int4_output)
print(f"INT4 ç›¸ä¼¼åº¦: {similarity}")  # æ¥å— > 96%
```

### 3. é—®é¢˜éš”ç¦»

é‡åˆ°é—®é¢˜æ—¶ï¼Œå…ˆç¡®å®šè¾¹ç•Œï¼š
```
é—®é¢˜: è½¬å½•ç»“æœä¸å¯¹

æ’æŸ¥æ­¥éª¤:
1. Encoder è¾“å‡ºå¯¹å—ï¼Ÿ â†’ éªŒè¯ä½™å¼¦ç›¸ä¼¼åº¦
2. Prompt æ„å»ºå¯¹å—ï¼Ÿ â†’ æ‰“å°å¯¹æ¯”å®˜æ–¹
3. Decoder æ¨ç†å¯¹å—ï¼Ÿ â†’ å•ç‹¬æµ‹è¯• Decoder
4. åå¤„ç†å¯¹å—ï¼Ÿ â†’ æ£€æŸ¥æ–‡æœ¬è§£ç 
```

### 4. æ€§èƒ½åˆ†æ

ä¸è¦ç›²ç›®ä¼˜åŒ–ï¼Œå…ˆ profileï¼š
```python
import cProfile
cProfile.run('transcribe(audio)', sort='cumulative')

# æ‰¾å‡ºçœŸæ­£çš„ç“¶é¢ˆ
# å¯èƒ½æ˜¯: æ¨¡å‹åŠ è½½? é¢„çƒ­? è§£ç ? åå¤„ç†?
```

---

## ğŸ“š ç›¸å…³æäº¤å‚è€ƒ

å¦‚æœä½ æƒ³æ·±å…¥äº†è§£æŸä¸ªé˜¶æ®µçš„ä»£ç ï¼Œå¯ä»¥æŸ¥çœ‹è¿™äº›æäº¤ï¼š

| é˜¶æ®µ | å…³é”®æäº¤ | è¯´æ˜ |
|------|----------|------|
| èµ·æ­¥ | `c556c2d` | åˆæ­¥æäº¤ |
| Encoder å¯¼å‡º | `f75b043` | ä½™å¼¦ç›¸ä¼¼åº¦éªŒè¯ |
| åˆ†ä½“ Encoder | `da0590c` | è§£å†³æ˜¾å­˜é—®é¢˜ |
| Decoder å¯¼å‡º | `ba5983e` | GGUF å¯¼å‡º |
| åŸºç¡€æ¨ç† | `c021cc0` | åˆæ­¥å¼•æ“ |
| æ—¶é—´æˆ³å¯¹é½ | `17c63f6` | é›†æˆ Aligner |
| é‡åŒ–ä¼˜åŒ– | `ab498eb` | INT4 é‡åŒ– |
| å¯åŠ¨ä¼˜åŒ– | `3917d4b` | ç»Ÿè®¡å¯åŠ¨æ—¶é—´ |
| å‘½ä»¤è¡Œå·¥å…· | `f157e09` | transcribe.py |
| æ‰“åŒ… | `4f9b7c5` | PyInstaller |

æŸ¥çœ‹å…·ä½“æäº¤çš„å‘½ä»¤ï¼š
```bash
git show f75b043  # æŸ¥çœ‹æŸä¸ªæäº¤çš„è¯¦ç»†å˜æ›´
git diff c556c2d..f75b043  # æŸ¥çœ‹ä¸¤ä¸ªæäº¤ä¹‹é—´çš„å·®å¼‚
```

---

**æ–‡æ¡£ç»“æŸ**
