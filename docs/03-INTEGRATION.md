# Qwen3-ASR-GGUF é›†æˆæŒ‡å—

> æ–‡æ¡£ç‰ˆæœ¬ï¼š1.0  
> æœ€åæ›´æ–°ï¼š2026-02-23  
> **æ¨èé˜…è¯»é¡ºåºï¼šç¬¬ â‘¡ é¡ºä½**ï¼ˆæ¶æ„ç†è§£åçš„å®æˆ˜æŒ‡å—ï¼‰

---

## ğŸ“‹ æœ¬æ–‡æ¡£é˜…è¯»æŒ‡å—

### åœ¨å®Œæ•´é¡¹ç›®æ–‡æ¡£ä¸­çš„é˜…è¯»é¡ºåº

| é¡ºä½ | æ–‡æ¡£ | æ–‡ä»¶å | ç›®æ ‡è¯»è€… | é¢„è®¡è€—æ—¶ |
|:----:|------|--------|----------|----------|
| **â‘ ** | [é¡¹ç›®æ¶æ„](./02-ARCHITECTURE.md) | `02-ARCHITECTURE.md` | æƒ³äº†è§£é¡¹ç›®æ•´ä½“è®¾è®¡ | 1-2 å°æ—¶ |
| **â‘¡** | **é›†æˆæŒ‡å—** | `03-INTEGRATION.md` | æƒ³å¿«é€Ÿä½¿ç”¨é¡¹ç›® | 1-2 å°æ—¶ |
| **â‘¢** | [å­¦ä¹ è®¡åˆ’](./06-LEARNING_PLAN.md) | `06-LEARNING_PLAN.md` | æƒ³æ·±å…¥ç†è§£åŸç† | 4-12 å‘¨ |
| **â‘£** | [å¯¼å‡ºæŒ‡å—](./EXPORT_GUIDE.md) | `EXPORT_GUIDE.md` | æƒ³è½¬æ¢è‡ªå·±çš„æ¨¡å‹ | 2-4 å°æ—¶ |
| **â‘¤** | [æºç è§£æ](./SOURCE_CODE.md) | `SOURCE_CODE.md` | æƒ³ä¿®æ”¹/æ‰©å±•åŠŸèƒ½ | 4-8 å‘¨ |

### æœ¬æ–‡æ¡£ç»“æ„

```
é˜…è¯»å»ºè®®ï¼šæ ¹æ®ä½ çš„éœ€æ±‚é€‰æ‹©é˜…è¯»è·¯å¾„

å¿«é€Ÿä½¿ç”¨è·¯å¾„ï¼š
  1. å¿«é€Ÿå¼€å§‹ â”€â”€â”€â”€â”€â”€â–¶ 5 åˆ†é’Ÿä¸Šæ‰‹
  2. å®‰è£…ä¸é…ç½® â”€â”€â”€â”€â–¶ ç¯å¢ƒæ­å»º
  3. Python é›†æˆ â”€â”€â”€â–¶ ä»£ç è°ƒç”¨

æ·±å…¥å­¦ä¹ è·¯å¾„ï¼š
  1. å¿«é€Ÿå¼€å§‹ â”€â”€â”€â”€â”€â”€â–¶ äº†è§£åŸºæœ¬ç”¨æ³•
  2. Python é›†æˆ â”€â”€â”€â–¶ å®Œæ•´ API ä½¿ç”¨
  3. é«˜çº§é…ç½® â”€â”€â”€â”€â”€â”€â–¶ æ€§èƒ½è°ƒä¼˜
  4. é”™è¯¯å¤„ç† â”€â”€â”€â”€â”€â–¶ é—®é¢˜æ’æŸ¥

éƒ¨ç½²åº”ç”¨è·¯å¾„ï¼š
  1. Web æœåŠ¡é›†æˆ â”€â”€â–¶ FastAPI éƒ¨ç½²
  2. æ‰¹é‡å¤„ç† â”€â”€â”€â”€â”€â–¶ å¤§è§„æ¨¡å¤„ç†
  3. Docker éƒ¨ç½² â”€â”€â”€â–¶ å®¹å™¨åŒ–éƒ¨ç½²
```

---

## ç›®å½•

1. [å¿«é€Ÿå¼€å§‹](#1-å¿«é€Ÿå¼€å§‹)
2. [å®‰è£…ä¸é…ç½®](#2-å®‰è£…ä¸é…ç½®)
3. [Python é›†æˆ](#3-python é›†æˆ)
4. [å‘½ä»¤è¡Œé›†æˆ](#4-å‘½ä»¤è¡Œé›†æˆ)
5. [Web æœåŠ¡é›†æˆ](#5-Web æœåŠ¡é›†æˆ)
6. [æ‰¹é‡å¤„ç†](#6-æ‰¹é‡å¤„ç†)
7. [é«˜çº§é…ç½®](#7-é«˜çº§é…ç½®)
8. [é”™è¯¯å¤„ç†ä¸è°ƒè¯•](#8-é”™è¯¯å¤„ç†ä¸è°ƒè¯•)
9. [æ€§èƒ½ä¼˜åŒ–](#9-æ€§èƒ½ä¼˜åŒ–)
10. [å¸¸è§é—®é¢˜](#10-å¸¸è§é—®é¢˜)

---

## 1. å¿«é€Ÿå¼€å§‹

### 1.1 æœ€å°å¯ç”¨ç¤ºä¾‹

```python
from qwen_asr_gguf.inference import QwenASREngine, ASREngineConfig

# é…ç½®å¼•æ“
config = ASREngineConfig(model_dir="model")

# åˆå§‹åŒ–å¼•æ“
engine = QwenASREngine(config)

# æ‰§è¡Œè½¬å½•
result = engine.transcribe("audio.mp3")

# è¾“å‡ºç»“æœ
print(result.text)

# å…³é—­å¼•æ“
engine.shutdown()
```

### 1.2 ä¸€è¡Œå‘½ä»¤è½¬å½•

```bash
python transcribe.py audio.mp3 -y
```

---

## 2. å®‰è£…ä¸é…ç½®

### 2.1 ç¯å¢ƒè¦æ±‚

| ç»„ä»¶ | æœ€ä½ç‰ˆæœ¬ | æ¨èç‰ˆæœ¬ |
|------|----------|----------|
| Python | 3.8+ | 3.10+ |
| æ“ä½œç³»ç»Ÿ | Windows 10 / macOS 10.15 / Linux | - |
| æ˜¾å­˜ | 4GB (CPU æ¨¡å¼) | 8GB+ (GPU æ¨¡å¼) |

### 2.2 å®‰è£…ä¾èµ–

#### åŸºç¡€ä¾èµ–

```bash
pip install -r requirements.txt
```

æ ¸å¿ƒä¾èµ–è¯´æ˜ï¼š

```txt
# æ¨¡å‹è½¬æ¢
transformers==4.57.6
torch
accelerate

# æ¨ç†å¼•æ“
onnxruntime-directml    # Windows DirectML
# æˆ–
onnxruntime-gpu         # Linux/Mac CUDA

gguf                    # GGUF æ ¼å¼æ”¯æŒ

# éŸ³é¢‘å¤„ç†
pydub                   # éŸ³é¢‘åŠ è½½
librosa                 # éŸ³é¢‘ç‰¹å¾ (å¯é€‰)
srt                     # å­—å¹•ç”Ÿæˆ

# åˆ†è¯æ”¯æŒ (å¯é€‰)
nagisa                  # æ—¥æ–‡åˆ†è¯
```

#### llama.cpp åŠ¨æ€åº“

ä» [llama.cpp Releases](https://github.com/ggml-org/llama.cpp/releases) ä¸‹è½½é¢„ç¼–è¯‘äºŒè¿›åˆ¶ï¼š

| å¹³å° | ä¸‹è½½æ–‡ä»¶ | è§£å‹åä½ç½® |
|------|----------|------------|
| **Windows (DML)** | `llama-bXXXX-bin-win-dml-x64.zip` | `qwen_asr_gguf/inference/bin/` |
| **Windows (Vulkan)** | `llama-bXXXX-bin-win-vulkan-x64.zip` | `qwen_asr_gguf/inference/bin/` |
| **macOS** | `llama-bXXXX-bin-macos-x64.zip` | `qwen_asr_gguf/inference/bin/` |
| **Linux** | éœ€ä»æºç ç¼–è¯‘ | `qwen_asr_gguf/inference/bin/` |

æ‰€éœ€ DLL æ–‡ä»¶ï¼š

```
qwen_asr_gguf/inference/bin/
â”œâ”€â”€ ggml.dll (æˆ– libggml.so / libggml.dylib)
â”œâ”€â”€ ggml-base.dll
â””â”€â”€ llama.dll (æˆ– libllama.so / libllama.dylib)
```

### 2.3 ä¸‹è½½æ¨¡å‹

#### æ–¹å¼ 1ï¼šä¸‹è½½é¢„è½¬æ¢æ¨¡å‹ï¼ˆæ¨èï¼‰

ä» [GitHub Releases](https://github.com/HaujetZhao/Qwen3-ASR-GGUF/releases/tag/models) ä¸‹è½½å·²è½¬æ¢å¥½çš„æ¨¡å‹ï¼š

```bash
# ä¸‹è½½åè§£å‹åˆ°é¡¹ç›®æ ¹ç›®å½•çš„ model æ–‡ä»¶å¤¹
# æ¨èä¸‹è½½é‡åŒ–ç‰ˆæœ¬ï¼ŒèŠ‚çœæ˜¾å­˜
```

#### æ–¹å¼ 2ï¼šæ‰‹åŠ¨è½¬æ¢æ¨¡å‹

```bash
# 1. ä¸‹è½½åŸå§‹æ¨¡å‹
pip install modelscope
modelscope download --model Qwen/Qwen3-ASR-1.7B
modelscope download --model Qwen/Qwen3-ForcedAligner-0.6B

# 2. é…ç½®è·¯å¾„ (export_config.py)
from pathlib import Path
model_home = Path('~/.cache/modelscope/hub/models/Qwen').expanduser()

ASR_MODEL_DIR = model_home / 'Qwen3-ASR-1.7B'
ALIGNER_MODEL_DIR = model_home / 'Qwen3-ForcedAligner-0.6B'
EXPORT_DIR = r'./model'

# 3. æ‰§è¡Œè½¬æ¢
python 01-Export-ASR-Encoder-Frontend.py
python 02-Export_ASR-Encoder-Backend.py
python 03-Optimize-ASR-Encoder.py
python 04-Quantize-ASR-Encoder.py
python 05-Export-ASR-Decoder-HF.py
python 06-Convert-ASR-Decoder-GGUF.py
python 07-Quantize-ASR-Decoder-GGUF.py

# Aligner æ¨¡å‹ (å¯é€‰)
python 11-Export-Aligner-Encoder-Frontend.py
# ... (12-17 æ­¥éª¤ç›¸åŒ)
```

### 2.4 éªŒè¯å®‰è£…

```python
# test_install.py
from qwen_asr_gguf.inference import QwenASREngine, ASREngineConfig
from pathlib import Path

# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
model_files = [
    "model/qwen3_asr_llm.q4_k.gguf",
    "model/qwen3_asr_encoder_frontend.int4.onnx",
    "model/qwen3_asr_encoder_backend.int4.onnx"
]

for f in model_files:
    if not Path(f).exists():
        print(f"âŒ ç¼ºå¤±æ¨¡å‹æ–‡ä»¶ï¼š{f}")
    else:
        print(f"âœ… æ¨¡å‹æ–‡ä»¶å­˜åœ¨ï¼š{f}")

# æµ‹è¯•åˆå§‹åŒ–
try:
    config = ASREngineConfig(model_dir="model")
    engine = QwenASREngine(config)
    print("âœ… å¼•æ“åˆå§‹åŒ–æˆåŠŸ")
    engine.shutdown()
except Exception as e:
    print(f"âŒ å¼•æ“åˆå§‹åŒ–å¤±è´¥ï¼š{e}")
```

---

## 3. Python é›†æˆ

### 3.1 åŸºç¡€é›†æˆ

#### 3.1.1 ç®€å•è½¬å½•

```python
from qwen_asr_gguf.inference import QwenASREngine, ASREngineConfig

def transcribe_audio(audio_path: str):
    """æœ€ç®€å•çš„è½¬å½•å‡½æ•°"""
    config = ASREngineConfig(model_dir="model")
    engine = QwenASREngine(config)
    
    try:
        result = engine.transcribe(audio_path)
        return result.text
    finally:
        engine.shutdown()

# ä½¿ç”¨ç¤ºä¾‹
text = transcribe_audio("meeting.mp3")
print(text)
```

#### 3.1.2 å¸¦é…ç½®çš„è½¬å½•

```python
from qwen_asr_gguf.inference import QwenASREngine, ASREngineConfig, AlignerConfig

# å®Œæ•´é…ç½®
config = ASREngineConfig(
    model_dir="/path/to/models",          # æ¨¡å‹ç›®å½•
    encoder_frontend_fn="qwen3_asr_encoder_frontend.int4.onnx",
    encoder_backend_fn="qwen3_asr_encoder_backend.int4.onnx",
    llm_fn="qwen3_asr_llm.q4_k.gguf",
    
    # ç¡¬ä»¶åŠ é€Ÿ
    use_dml=True,              # Windows DirectML
    n_ctx=2048,                # ä¸Šä¸‹æ–‡çª—å£
    
    # æµå¼é…ç½®
    chunk_size=40.0,           # æ¯ç‰‡ 40 ç§’
    memory_num=1,              # è®°å¿† 1 ä¸ªå†å²ç‰‡æ®µ
    
    # å¯¹é½é…ç½®
    enable_aligner=True,
    align_config=AlignerConfig(
        use_dml=True,
        model_dir="/path/to/models"
    ),
    
    verbose=True
)

engine = QwenASREngine(config)
result = engine.transcribe(
    audio_file="audio.mp3",
    context="ä¼šè®®å½•éŸ³ï¼ŒåŒ…å«æŠ€æœ¯è®¨è®º",  # ä¸Šä¸‹æ–‡æç¤º
    language="Chinese",              # å¼ºåˆ¶è¯­è¨€
    temperature=0.4                  # é‡‡æ ·æ¸©åº¦
)

print(f"è½¬å½•æ–‡æœ¬ï¼š{result.text}")
print(f"æ€§èƒ½ç»Ÿè®¡ï¼š{result.performance}")

if result.alignment:
    print(f"å­—çº§æ—¶é—´æˆ³ï¼š{len(result.alignment.items)} ä¸ª")

engine.shutdown()
```

### 3.2 ç»“æœå¤„ç†

#### 3.2.1 å¯¼å‡ºç»“æœ

```python
from qwen_asr_gguf.inference import exporters

# å¯¼å‡º TXT
exporters.export_to_txt("output.txt", result)

# å¯¼å‡º SRT å­—å¹•
exporters.export_to_srt("output.srt", result)

# å¯¼å‡º JSON æ—¶é—´æˆ³
exporters.export_to_json("output.json", result)
```

#### 3.2.2 è‡ªå®šä¹‰åå¤„ç†

```python
from qwen_asr_gguf.inference import chinese_itn

# ä¸­æ–‡æ•°å­—è§„æ•´
text = result.text
normalized = chinese_itn.chinese_to_num(text)

# ç¤ºä¾‹ï¼š'äºŒé›¶äºŒäº”å¹´' â†’ '2025 å¹´'
#      'ä¸€ç™¾äºŒåä¸‰äºº' â†’ '123 äºº'
```

#### 3.2.3 è®¿é—®å¯¹é½ç»“æœ

```python
if result.alignment:
    for item in result.alignment.items[:10]:  # å‰ 10 ä¸ªå­—
        print(f"{item.text}: {item.start_time:.3f}s - {item.end_time:.3f}s")
    
    # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
    items_dict = [
        {
            "text": item.text,
            "start": item.start_time,
            "end": item.end_time
        }
        for item in result.alignment.items
    ]
```

### 3.3 éŸ³é¢‘åˆ‡ç‰‡å¤„ç†

#### 3.3.1 æŒ‡å®šæ—¶é—´èŒƒå›´

```python
# ä»ç¬¬ 30 ç§’å¼€å§‹ï¼Œè¯»å– 60 ç§’
result = engine.transcribe(
    audio_file="long_audio.mp3",
    start_second=30.0,
    duration=60.0
)
```

#### 3.3.2 åˆ†æ®µå¤„ç†é•¿éŸ³é¢‘

```python
def process_long_audio(engine, audio_path, chunk_minutes=10):
    """å¤„ç†è¶…é•¿éŸ³é¢‘ï¼Œåˆ†æ®µè½¬å½•"""
    from qwen_asr_gguf.inference.utils import load_audio
    
    # åŠ è½½éŸ³é¢‘è·å–æ€»æ—¶é•¿
    audio = load_audio(audio_path)
    total_duration = len(audio) / 16000  # ç§’
    
    results = []
    chunk_seconds = chunk_minutes * 60
    
    for start in range(0, int(total_duration), chunk_seconds):
        duration = min(chunk_seconds, total_duration - start)
        
        result = engine.transcribe(
            audio_file=audio_path,
            start_second=start,
            duration=duration,
            context=f"ç¬¬ {start//60 + 1} æ®µ"
        )
        
        results.append({
            "start": start,
            "duration": duration,
            "text": result.text
        })
        
        print(f"å®Œæˆç‰‡æ®µï¼š{start}s - {start+duration}s")
    
    return results

# ä½¿ç”¨ç¤ºä¾‹
segments = process_long_audio(engine, "lecture.mp3", chunk_minutes=10)
full_text = "\n".join([s["text"] for s in segments])
```

### 3.4 å¤šè¯­è¨€æ”¯æŒ

```python
SUPPORTED_LANGUAGES = [
    "Chinese", "English", "Cantonese",
    "Japanese", "Korean", "French", "German",
    "Spanish", "Russian", "Arabic", "Thai",
    "Vietnamese", "Indonesian", "Hindi"
    # ... å…± 28 ç§è¯­è¨€
]

# è‡ªåŠ¨è¯­è¨€è¯†åˆ« (é»˜è®¤)
result = engine.transcribe(audio_path, language=None)

# å¼ºåˆ¶æŒ‡å®šè¯­è¨€
result = engine.transcribe(audio_path, language="English")

# ä¸­è‹±æ··åˆ (æ¨èç”¨ Chineseï¼Œæ¨¡å‹å¯å¤„ç†æ··åˆ)
result = engine.transcribe(audio_path, language="Chinese")
```

---

## 4. å‘½ä»¤è¡Œé›†æˆ

### 4.1 åŸºç¡€ç”¨æ³•

```bash
# åŸºæœ¬è½¬å½•
python transcribe.py audio.mp3

# è¾“å‡ºåˆ°æŒ‡å®šæ–‡ä»¶
python transcribe.py audio.mp3 -m ./model --prec int4
```

### 4.2 å®Œæ•´å‚æ•°è¯´æ˜

```bash
python transcribe.py audio.mp3 \
    # === æ¨¡å‹é…ç½® ===
    --model-dir ./model \
    --prec int4 \              # fp32, fp16, int8, int4
    --timestamp / --no-ts \    # æ—¶é—´æˆ³å¯¹é½
    --dml / --no-dml \         # DirectML åŠ é€Ÿ
    --vulkan / --no-vulkan \   # Vulkan åŠ é€Ÿ
    --n-ctx 2048 \             # ä¸Šä¸‹æ–‡çª—å£
    
    # === è½¬å½•è®¾ç½® ===
    --language Chinese \       # å¼ºåˆ¶è¯­ç§
    --context "ä¼šè®®å½•éŸ³" \      # ä¸Šä¸‹æ–‡æç¤º
    --temperature 0.4 \        # é‡‡æ ·æ¸©åº¦
    
    # === éŸ³é¢‘åˆ‡ç‰‡ ===
    --seek-start 30 \          # å¼€å§‹ä½ç½® (ç§’)
    --duration 60 \            # å¤„ç†æ—¶é•¿ (ç§’)
    
    # === æµå¼é…ç½® ===
    --chunk-size 40 \          # åˆ†æ®µæ—¶é•¿ (ç§’)
    --memory-num 1 \           # è®°å¿†ç‰‡æ®µæ•°
    
    # === å…¶ä»– ===
    --verbose / --quiet \      # è¯¦ç»†æ—¥å¿—
    --yes                      # è¦†ç›–å·²å­˜åœ¨æ–‡ä»¶
```

### 4.3 æ‰¹å¤„ç†è„šæœ¬

#### Windows Batch

```batch
@echo off
set MODEL_DIR=model
set OUTPUT_DIR=output

if not exist "%OUTPUT_DIR%" mkdir "%OUTPUT_DIR%"

for %%f in (audio\*.mp3) do (
    echo æ­£åœ¨å¤„ç†ï¼š%%f
    python transcribe.py "%%f" ^
        --model-dir %MODEL_DIR% ^
        --prec int4 ^
        --dml ^
        --yes
)

echo æ‰¹é‡å¤„ç†å®Œæˆ
```

#### Linux/Mac Shell

```bash
#!/bin/bash

MODEL_DIR="model"
OUTPUT_DIR="output"

mkdir -p "$OUTPUT_DIR"

for file in audio/*.mp3; do
    echo "Processing: $file"
    python transcribe.py "$file" \
        --model-dir "$MODEL_DIR" \
        --prec int4 \
        --dml \
        --yes
done

echo "Batch processing complete"
```

#### Python æ‰¹é‡å¤„ç†

```python
from pathlib import Path
from qwen_asr_gguf.inference import QwenASREngine, ASREngineConfig, exporters

def batch_transcribe(audio_folder: str, output_folder: str):
    """æ‰¹é‡è½¬å½•æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰éŸ³é¢‘"""
    config = ASREngineConfig(model_dir="model")
    engine = QwenASREngine(config)
    
    try:
        audio_files = list(Path(audio_folder).glob("*.mp3"))
        audio_files.extend(Path(audio_folder).glob("*.wav"))
        audio_files.extend(Path(audio_folder).glob("*.m4a"))
        
        for audio_path in audio_files:
            print(f"\nå¤„ç†ï¼š{audio_path.name}")
            
            result = engine.transcribe(str(audio_path))
            
            # å¯¼å‡ºç»“æœ
            base_name = audio_path.stem
            exporters.export_to_txt(f"{output_folder}/{base_name}.txt", result)
            exporters.export_to_srt(f"{output_folder}/{base_name}.srt", result)
            exporters.export_to_json(f"{output_folder}/{base_name}.json", result)
            
    finally:
        engine.shutdown()

# ä½¿ç”¨ç¤ºä¾‹
batch_transcribe("audio_files", "transcriptions")
```

---

## 5. Web æœåŠ¡é›†æˆ

### 5.1 FastAPI æœåŠ¡

```python
# server.py
from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import Optional, List
import tempfile
import os

from qwen_asr_gguf.inference import QwenASREngine, ASREngineConfig, exporters

app = FastAPI(title="Qwen3-ASR Service")

# å…¨å±€å¼•æ“ (å•ä¾‹)
engine = None

@app.on_event("startup")
async def startup_event():
    """æœåŠ¡å¯åŠ¨æ—¶åˆå§‹åŒ–å¼•æ“"""
    global engine
    config = ASREngineConfig(
        model_dir="model",
        use_dml=True,
        enable_aligner=True
    )
    engine = QwenASREngine(config)
    print("ASR Engine initialized")

@app.on_event("shutdown")
async def shutdown_event():
    """æœåŠ¡å…³é—­æ—¶é‡Šæ”¾èµ„æº"""
    global engine
    if engine:
        engine.shutdown()

class TranscribeRequest(BaseModel):
    language: Optional[str] = None
    context: Optional[str] = None
    temperature: float = 0.4

class TranscribeResponse(BaseModel):
    text: str
    duration: float
    performance: dict
    srt_available: bool
    json_available: bool

@app.post("/transcribe", response_model=TranscribeResponse)
async def transcribe(
    file: UploadFile = File(...),
    language: Optional[str] = None,
    context: Optional[str] = None,
    temperature: float = 0.4
):
    """è½¬å½•ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶"""
    if not file.filename.lower().endswith(('.mp3', '.wav', '.m4a', '.flac')):
        raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„éŸ³é¢‘æ ¼å¼")
    
    # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
        content = await file.read()
        tmp.write(content)
        tmp_path = tmp.name
    
    try:
        # æ‰§è¡Œè½¬å½•
        result = engine.transcribe(
            audio_file=tmp_path,
            language=language,
            context=context,
            temperature=temperature
        )
        
        # å¯¼å‡º SRT å’Œ JSON
        srt_path = tmp_path + ".srt"
        json_path = tmp_path + ".json"
        exporters.export_to_srt(srt_path, result)
        exporters.export_to_json(json_path, result)
        
        return TranscribeResponse(
            text=result.text,
            duration=result.performance.get('total_time', 0),
            performance=result.performance,
            srt_available=os.path.exists(srt_path),
            json_available=os.path.exists(json_path)
        )
        
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        for path in [tmp_path, tmp_path + ".srt", tmp_path + ".json"]:
            if os.path.exists(path):
                os.remove(path)

@app.get("/health")
async def health_check():
    return {"status": "healthy"}

# å¯åŠ¨æœåŠ¡
# uvicorn server:app --host 0.0.0.0 --port 8000
```

### 5.2 å®¢æˆ·ç«¯è°ƒç”¨ç¤ºä¾‹

```python
import requests

# ä¸Šä¼ æ–‡ä»¶è½¬å½•
with open("audio.mp3", "rb") as f:
    files = {"file": f}
    data = {
        "language": "Chinese",
        "context": "æŠ€æœ¯ä¼šè®®å½•éŸ³",
        "temperature": 0.4
    }
    
    response = requests.post(
        "http://localhost:8000/transcribe",
        files=files,
        data=data
    )
    
    result = response.json()
    print(f"è½¬å½•æ–‡æœ¬ï¼š{result['text']}")
    print(f"å¤„ç†è€—æ—¶ï¼š{result['duration']:.2f}ç§’")
```

### 5.3 Docker éƒ¨ç½²

```dockerfile
# Dockerfile
FROM python:3.10-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    ffmpeg \
    && rm -rf /var/lib/apt/lists/*

# å®‰è£… Python ä¾èµ–
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨
COPY . .

# ä¸‹è½½æ¨¡å‹ (æˆ–ä½¿ç”¨æŒ‚è½½å·)
# RUN python download_models.py

EXPOSE 8000

CMD ["uvicorn", "server:app", "--host", "0.0.0.0", "--port", "8000"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  asr-service:
    build: .
    ports:
      - "8000:8000"
    volumes:
      - ./model:/app/model
      - ./uploads:/app/uploads
    environment:
      - PYTHONUNBUFFERED=1
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

---

## 6. æ‰¹é‡å¤„ç†

### 6.1 å¤šæ–‡ä»¶å¹¶è¡Œå¤„ç†

```python
from concurrent.futures import ThreadPoolExecutor, as_completed
from qwen_asr_gguf.inference import QwenASREngine, ASREngineConfig

def transcribe_single_file(args):
    """å•æ–‡ä»¶è½¬å½•å‡½æ•°"""
    audio_path, config_data = args
    
    # æ¯ä¸ªçº¿ç¨‹ç‹¬ç«‹å¼•æ“å®ä¾‹
    config = ASREngineConfig(**config_data)
    engine = QwenASREngine(config)
    
    try:
        result = engine.transcribe(audio_path)
        return {
            "file": audio_path,
            "text": result.text,
            "success": True
        }
    except Exception as e:
        return {
            "file": audio_path,
            "error": str(e),
            "success": False
        }
    finally:
        engine.shutdown()

def batch_parallel(audio_files, max_workers=4):
    """å¹¶è¡Œæ‰¹é‡å¤„ç†"""
    config_data = {
        "model_dir": "model",
        "use_dml": True,
        "verbose": False
    }
    
    args_list = [(f, config_data) for f in audio_files]
    results = {}
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {executor.submit(transcribe_single_file, args): args[0] 
                   for args in args_list}
        
        for future in as_completed(futures):
            result = future.result()
            if result["success"]:
                print(f"âœ… {result['file']}: {len(result['text'])} å­—ç¬¦")
            else:
                print(f"âŒ {result['file']}: {result['error']}")
            results[result['file']] = result
    
    return results

# ä½¿ç”¨ç¤ºä¾‹
audio_files = ["file1.mp3", "file2.mp3", "file3.mp3"]
results = batch_parallel(audio_files, max_workers=2)
```

### 6.2 è¿›åº¦è¿½è¸ª

```python
from tqdm import tqdm
from qwen_asr_gguf.inference import QwenASREngine, ASREngineConfig, exporters

def batch_with_progress(audio_folder: str, output_folder: str):
    """å¸¦è¿›åº¦æ¡çš„æ‰¹é‡å¤„ç†"""
    from pathlib import Path
    
    audio_files = list(Path(audio_folder).glob("*.mp3"))
    
    config = ASREngineConfig(model_dir="model", verbose=False)
    engine = QwenASREngine(config)
    
    try:
        for audio_path in tqdm(audio_files, desc="å¤„ç†éŸ³é¢‘"):
            result = engine.transcribe(str(audio_path))
            
            base_name = audio_path.stem
            exporters.export_to_txt(f"{output_folder}/{base_name}.txt", result)
            
    finally:
        engine.shutdown()
```

---

## 7. é«˜çº§é…ç½®

### 7.1 ç¡¬ä»¶åŠ é€Ÿé…ç½®

#### DirectML (Windows)

```python
config = ASREngineConfig(
    model_dir="model",
    use_dml=True,  # å¯ç”¨ DirectML
)

# ç¯å¢ƒå˜é‡é…ç½®
import os
os.environ["GGML_DIRECTML_LOG"] = "0"  # 0=å…³é—­æ—¥å¿—
```

#### Vulkan (è·¨å¹³å°)

```python
config = ASREngineConfig(
    model_dir="model",
    use_dml=False,
)

# Vulkan ç¯å¢ƒå˜é‡
import os
os.environ["GGML_VULKAN_DEVICE"] = "0"  # é€‰æ‹© GPU è®¾å¤‡
os.environ["GGML_VULKAN_LOG"] = "0"

# Intel é›†æ˜¾ FP16 é—®é¢˜
os.environ["GGML_VULKAN_DISABLE_F16"] = "1"
```

#### CPU æ¨¡å¼

```python
config = ASREngineConfig(
    model_dir="model",
    use_dml=False,
    n_ctx=1024,  # å‡å°ä¸Šä¸‹æ–‡èŠ‚çœå†…å­˜
)
```

### 7.2 æ€§èƒ½è°ƒä¼˜å‚æ•°

```python
config = ASREngineConfig(
    model_dir="model",
    
    # ä¸Šä¸‹æ–‡çª—å£ (è¶Šå¤§è¶Šå æ˜¾å­˜ï¼Œä½†ä¸Šä¸‹æ–‡æ›´é•¿)
    n_ctx=2048,
    
    # æµå¼åˆ‡ç‰‡
    chunk_size=40.0,    # æ¯ç‰‡ç§’æ•° (é»˜è®¤ 40s)
    memory_num=1,       # è®°å¿†å†å²ç‰‡æ®µæ•° (0=æ— è®°å¿†)
    
    # å¯¹é½å¼•æ“
    enable_aligner=True,
)
```

### 7.3 ä¸Šä¸‹æ–‡æç¤ºä¼˜åŒ–

```python
# åœºæ™¯ 1ï¼šä¼šè®®å½•éŸ³
context = "ä¼šè®®å½•éŸ³ï¼ŒåŒ…å«å¤šä½å‘è¨€äººè®¨è®ºæŠ€æœ¯æ–¹æ¡ˆ"

# åœºæ™¯ 2ï¼šæ’­å®¢èŠ‚ç›®
context = "æ’­å®¢èŠ‚ç›®ï¼Œä¸»æŒäººå’Œå˜‰å®¾å¯¹è¯"

# åœºæ™¯ 3ï¼šä¸“ä¸šé¢†åŸŸ
context = "åŒ»å­¦è®²åº§ï¼ŒåŒ…å«ä¸“ä¸šæœ¯è¯­"

# åœºæ™¯ 4ï¼šå¸¦ä¸“æœ‰åè¯
context = "äº§å“å‘å¸ƒä¼šï¼ŒæåŠ iPhoneã€MacBookã€Apple Watch ç­‰äº§å“"

result = engine.transcribe(audio_path, context=context)
```

### 7.4 è‡ªå®šä¹‰å¯¼å‡ºæ ¼å¼

```python
from qwen_asr_gguf.inference.schema import TranscribeResult
import json

def export_custom_format(result: TranscribeResult, output_path: str):
    """è‡ªå®šä¹‰ JSON å¯¼å‡º"""
    data = {
        "full_text": result.text,
        "segments": [],
        "performance": result.performance
    }
    
    if result.alignment:
        data["word_level"] = [
            {
                "text": item.text,
                "start": round(item.start_time, 3),
                "end": round(item.end_time, 3)
            }
            for item in result.alignment.items
        ]
    
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
```

---

## 8. é”™è¯¯å¤„ç†ä¸è°ƒè¯•

### 8.1 å¸¸è§é”™è¯¯å¤„ç†

```python
from qwen_asr_gguf.inference import QwenASREngine, ASREngineConfig
import os

def safe_transcribe(audio_path: str):
    """å¸¦é”™è¯¯å¤„ç†çš„è½¬å½•"""
    
    # 1. æ£€æŸ¥æ–‡ä»¶å­˜åœ¨
    if not os.path.exists(audio_path):
        print(f"é”™è¯¯ï¼šæ–‡ä»¶ä¸å­˜åœ¨ {audio_path}")
        return None
    
    # 2. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    required_files = [
        "model/qwen3_asr_llm.q4_k.gguf",
        "model/qwen3_asr_encoder_frontend.int4.onnx",
        "model/qwen3_asr_encoder_backend.int4.onnx"
    ]
    
    for f in required_files:
        if not os.path.exists(f):
            print(f"é”™è¯¯ï¼šæ¨¡å‹æ–‡ä»¶ç¼ºå¤± {f}")
            return None
    
    config = ASREngineConfig(model_dir="model")
    engine = None
    
    try:
        engine = QwenASREngine(config)
        result = engine.transcribe(audio_path)
        return result
        
    except RuntimeError as e:
        if "è¾…åŠ©è¿›ç¨‹å¯åŠ¨å¤±è´¥" in str(e):
            print("é”™è¯¯ï¼šè¾…åŠ©è¿›ç¨‹å¯åŠ¨å¤±è´¥ï¼Œæ£€æŸ¥ ONNX æ¨¡å‹")
        elif "æ¨¡å‹åŠ è½½å¤±è´¥" in str(e):
            print("é”™è¯¯ï¼šGGUF æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œæ£€æŸ¥æ–‡ä»¶å®Œæ•´æ€§")
        else:
            print(f"è¿è¡Œæ—¶é”™è¯¯ï¼š{e}")
        return None
        
    except FileNotFoundError as e:
        print(f"æ–‡ä»¶é”™è¯¯ï¼š{e}")
        return None
        
    except Exception as e:
        print(f"æœªçŸ¥é”™è¯¯ï¼š{e}")
        return None
        
    finally:
        if engine:
            engine.shutdown()
```

### 8.2 è°ƒè¯•æ¨¡å¼

```python
import logging

# å¯ç”¨è¯¦ç»†æ—¥å¿—
logging.basicConfig(level=logging.DEBUG)

config = ASREngineConfig(
    model_dir="model",
    verbose=True  # æ‰“å°è¯¦ç»†ä¿¡æ¯
)

engine = QwenASREngine(config)
```

### 8.3 æ€§èƒ½åˆ†æ

```python
import cProfile
import pstats

def profile_transcribe():
    config = ASREngineConfig(model_dir="model")
    engine = QwenASREngine(config)
    
    profiler = cProfile.Profile()
    profiler.enable()
    
    result = engine.transcribe("test.mp3")
    
    profiler.disable()
    
    # è¾“å‡ºæ€§èƒ½ç»Ÿè®¡
    stats = pstats.Stats(profiler)
    stats.sort_stats('cumulative')
    stats.print_stats(20)  # æ˜¾ç¤ºå‰ 20 ä¸ªè€—æ—¶å‡½æ•°
    
    engine.shutdown()

profile_transcribe()
```

---

## 9. æ€§èƒ½ä¼˜åŒ–

### 9.1 æ˜¾å­˜ä¼˜åŒ–

```python
# æ–¹æ¡ˆ 1ï¼šå‡å°ä¸Šä¸‹æ–‡çª—å£
config = ASREngineConfig(n_ctx=1024)  # é»˜è®¤ 2048

# æ–¹æ¡ˆ 2ï¼šå‡å°‘è®°å¿†ç‰‡æ®µ
config = ASREngineConfig(memory_num=0)  # ç¦ç”¨è®°å¿†

# æ–¹æ¡ˆ 3ï¼šä½¿ç”¨æ›´å°æ¨¡å‹
# ä½¿ç”¨ 0.6B è€Œé 1.7B

# æ–¹æ¡ˆ 4ï¼šé™ä½ç²¾åº¦
# ä½¿ç”¨ INT4 Encoder + Q4_K Decoder
```

### 9.2 é€Ÿåº¦ä¼˜åŒ–

```python
# æ–¹æ¡ˆ 1ï¼šå¯ç”¨ GPU åŠ é€Ÿ
config = ASREngineConfig(use_dml=True)  # Windows
# æˆ–
os.environ["GGML_VULKAN"] = "1"  # è·¨å¹³å°

# æ–¹æ¡ˆ 2ï¼šå¢å¤§ chunk_size (å‡å°‘ç‰‡æ®µæ•°é‡)
config = ASREngineConfig(chunk_size=60.0)  # é»˜è®¤ 40s

# æ–¹æ¡ˆ 3ï¼šç¦ç”¨å¯¹é½ (å¦‚æœä¸éœ€è¦æ—¶é—´æˆ³)
config = ASREngineConfig(enable_aligner=False)
```

### 9.3 æ˜¾å­˜å ç”¨å‚è€ƒ

| é…ç½® | ASR Encoder | ASR Decoder | Aligner | æ€»è®¡ |
|------|-------------|-------------|---------|------|
| DML (INT4+Q4_K) | 473MB | - | - | ~0.5GB |
| Vulkan (INT4+Q4_K) | 420MB | 1.6GB | 0.9GB | ~2.9GB |
| CPU | - | - | - | ç³»ç»Ÿå†…å­˜ |

---

## 10. å¸¸è§é—®é¢˜

### Q1: è¾“å‡ºä¹±ç æˆ–ã€Œ!!!!ã€

**åŸå› **: Intel é›†æ˜¾ FP16 è®¡ç®—æº¢å‡º

**è§£å†³**:
```python
import os
os.environ["GGML_VULKAN_DISABLE_F16"] = "1"
```

### Q2: æ˜¾å­˜ä¸è¶³

**è§£å†³**:
```python
# 1. å‡å°ä¸Šä¸‹æ–‡
config.n_ctx = 1024

# 2. ç¦ç”¨è®°å¿†
config.memory_num = 0

# 3. ä½¿ç”¨ CPU æ¨¡å¼
config.use_dml = False
```

### Q3: é€Ÿåº¦è¿‡æ…¢

**è§£å†³**:
```python
# 1. å¯ç”¨ GPU
config.use_dml = True

# 2. å¢å¤§åˆ‡ç‰‡
config.chunk_size = 60.0

# 3. ç¦ç”¨å¯¹é½
config.enable_aligner = False
```

### Q4: æ¨¡å‹æ–‡ä»¶æ‰¾ä¸åˆ°

**æ£€æŸ¥**:
```python
from pathlib import Path

model_files = [
    "model/qwen3_asr_llm.q4_k.gguf",
    "model/qwen3_asr_encoder_frontend.int4.onnx",
    "model/qwen3_asr_encoder_backend.int4.onnx"
]

for f in model_files:
    print(f"{f}: {Path(f).exists()}")
```

### Q5: éŸ³é¢‘æ ¼å¼ä¸æ”¯æŒ

**æ”¯æŒæ ¼å¼**:
- MP3, WAV, M4A, FLAC, OGG, WMA

**è½¬æ¢**:
```python
from pydub import AudioSegment

audio = AudioSegment.from_file("input.aac")
audio.export("output.wav", format="wav")
```

---

## é™„å½• A: API å‚è€ƒ

### ASREngineConfig

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| model_dir | str | - | æ¨¡å‹ç›®å½• |
| encoder_frontend_fn | str | qwen3_asr_encoder_frontend.int4.onnx | å‰ç«¯æ¨¡å‹ |
| encoder_backend_fn | str | qwen3_asr_encoder_backend.int4.onnx | åç«¯æ¨¡å‹ |
| llm_fn | str | qwen3_asr_llm.q4_k.gguf | LLM æ¨¡å‹ |
| use_dml | bool | False | DirectML åŠ é€Ÿ |
| n_ctx | int | 2048 | ä¸Šä¸‹æ–‡çª—å£ |
| chunk_size | float | 40.0 | åˆ‡ç‰‡ç§’æ•° |
| memory_num | int | 1 | è®°å¿†ç‰‡æ®µæ•° |
| enable_aligner | bool | False | å¯ç”¨å¯¹é½ |
| align_config | AlignerConfig | None | å¯¹é½é…ç½® |
| verbose | bool | True | è¯¦ç»†æ—¥å¿— |

### QwenASREngine.transcribe()

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| audio_file | str | - | éŸ³é¢‘æ–‡ä»¶è·¯å¾„ |
| language | str | None | å¼ºåˆ¶è¯­è¨€ |
| context | str | None | ä¸Šä¸‹æ–‡æç¤º |
| start_second | float | 0.0 | å¼€å§‹ä½ç½® |
| duration | float | None | å¤„ç†æ—¶é•¿ |
| temperature | float | 0.4 | é‡‡æ ·æ¸©åº¦ |

### TranscribeResult

| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| text | str | è½¬å½•æ–‡æœ¬ |
| alignment | ForcedAlignResult | å¯¹é½ç»“æœ (å¯é€‰) |
| performance | dict | æ€§èƒ½ç»Ÿè®¡ |

---

## é™„å½• B: æ”¯æŒçš„è¯­è¨€

Chinese, English, Cantonese, Arabic, German, French, Spanish, Portuguese, Indonesian, Italian, Korean, Russian, Thai, Vietnamese, Japanese, Turkish, Hindi, Malay, Dutch, Swedish, Danish, Finnish, Polish, Czech, Filipino, Persian, Greek, Romanian, Hungarian, Macedonian

---

**æ–‡æ¡£ç»“æŸ**
